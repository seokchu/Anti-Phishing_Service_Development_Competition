{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ›¡ï¸ ScamShield Family v8.2\n",
                "## AI ê¸°ë°˜ ê°€ì¡± ë³´í˜¸í˜• í”¼ì‹±Â·ìŠ¤ìº  ì˜ˆë°© í”Œë«í¼\n",
                "\n",
                "### v8.2 í•µì‹¬ ê°œì„ \n",
                "- âœ… **100ì  ë§Œì **: ì§ê´€ì ì¸ ì ìˆ˜ ì²´ê³„ (AI 30ì  + ë©”íƒ€ 70ì )\n",
                "- âœ… **ìƒì„¸ ê²°ê³¼ ì¶œë ¥**: ë©”íƒ€ í•­ëª©ë³„ ì ìˆ˜ breakdown\n",
                "- âœ… **ë©”íƒ€ë°ì´í„° í‘œì‹œ**: í…ŒìŠ¤íŠ¸ ì…ë ¥ ì„¤ì • ëª…ì‹œ\n",
                "- âœ… **í•œê¸€ í°íŠ¸ ìˆ˜ì •**: matplotlib inline + NanumGothic\n",
                "- âœ… **Multi-Guardian**: ë³´í˜¸ì ì•Œë¦¼ ì‹œìŠ¤í…œ"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. í™˜ê²½ ì„¤ì •"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q transformers datasets torch scikit-learn pandas matplotlib seaborn accelerate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ========================================\n",
                "# v8.2: matplotlib inline ì„¤ì • (í•„ìˆ˜!)\n",
                "# matplotlib.use('Agg') ì‚¬ìš© ê¸ˆì§€ - í™”ë©´ì— ê·¸ë˜í”„ ì•ˆ ë³´ì„\n",
                "# ========================================\n",
                "%matplotlib inline\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "import os\n",
                "os.environ['PYTHONIOENCODING'] = 'utf-8'\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.font_manager as fm\n",
                "import seaborn as sns\n",
                "from datetime import datetime\n",
                "from typing import Dict, List, Optional\n",
                "import random\n",
                "import re\n",
                "import platform\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, precision_recall_fscore_support\n",
                "from sklearn.utils.class_weight import compute_class_weight\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
                "from datasets import Dataset as HFDataset\n",
                "\n",
                "# ========================================\n",
                "# í•œê¸€ í°íŠ¸ ì„¤ì • (v8.2 ìˆ˜ì •)\n",
                "# - %matplotlib inline ì‚¬ìš© (Agg ë°±ì—”ë“œ ì‚¬ìš© ê¸ˆì§€)\n",
                "# - NanumGothic ì§ì ‘ ì„¤ì •\n",
                "# ========================================\n",
                "def setup_korean_font():\n",
                "    \"\"\"í•œê¸€ í°íŠ¸ ì„¤ì • (ë‚˜ëˆ”ê³ ë”• ìš°ì„ )\"\"\"\n",
                "    \n",
                "    # 1. rcParamsë¡œ ì§ì ‘ NanumGothic ì„¤ì • ì‹œë„\n",
                "    try:\n",
                "        plt.rcParams['font.family'] = 'NanumGothic'\n",
                "        plt.rcParams['axes.unicode_minus'] = False\n",
                "        # í…ŒìŠ¤íŠ¸ - ì˜¤ë¥˜ ì—†ìœ¼ë©´ ì„±ê³µ\n",
                "        fig = plt.figure(figsize=(1,1))\n",
                "        plt.text(0.5, 0.5, 'í…ŒìŠ¤íŠ¸')\n",
                "        plt.close(fig)\n",
                "        return 'NanumGothic (rcParams)'\n",
                "    except:\n",
                "        pass\n",
                "    \n",
                "    # 2. ë‚˜ëˆ”ê³ ë”• íŒŒì¼ ê²½ë¡œ ì§ì ‘ ì¶”ê°€\n",
                "    nanum_paths = [\n",
                "        '/Library/Fonts/NanumGothic.ttf',\n",
                "        '/Library/Fonts/NanumGothic.otf',\n",
                "        os.path.expanduser('~/Library/Fonts/NanumGothic.ttf'),\n",
                "        os.path.expanduser('~/Library/Fonts/NanumGothic.otf'),\n",
                "        '/System/Library/Fonts/Supplemental/NanumGothic.ttf',\n",
                "        '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',\n",
                "    ]\n",
                "    \n",
                "    for path in nanum_paths:\n",
                "        if os.path.exists(path):\n",
                "            fm.fontManager.addfont(path)\n",
                "            font_prop = fm.FontProperties(fname=path)\n",
                "            plt.rcParams['font.family'] = font_prop.get_name()\n",
                "            plt.rcParams['axes.unicode_minus'] = False\n",
                "            return f'{font_prop.get_name()} ({path})'\n",
                "    \n",
                "    # 3. ì‹œìŠ¤í…œì—ì„œ í•œê¸€ í°íŠ¸ ê²€ìƒ‰\n",
                "    korean_fonts = [f.name for f in fm.fontManager.ttflist \n",
                "                    if any(x in f.name.lower() for x in ['nanum', 'gothic', 'gulim', 'malgun', 'dotum'])]\n",
                "    if korean_fonts:\n",
                "        plt.rcParams['font.family'] = korean_fonts[0]\n",
                "        plt.rcParams['axes.unicode_minus'] = False\n",
                "        return korean_fonts[0]\n",
                "    \n",
                "    # 4. í´ë°±: AppleGothic (Mac ê¸°ë³¸)\n",
                "    if platform.system() == 'Darwin':\n",
                "        plt.rcParams['font.family'] = 'AppleGothic'\n",
                "        plt.rcParams['axes.unicode_minus'] = False\n",
                "        return 'AppleGothic (fallback)'\n",
                "    \n",
                "    return 'Default (í•œê¸€ ê¹¨ì§ˆ ìˆ˜ ìˆìŒ)'\n",
                "\n",
                "font_name = setup_korean_font()\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "sns.set_style('whitegrid')\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'âœ… Device: {device}')\n",
                "print(f'âœ… í•œê¸€ í°íŠ¸: {font_name}')\n",
                "print(f'\\nğŸ’¡ ì°¸ê³ : ì‹œê°í™”ê°€ ì•ˆ ë³´ì´ë©´ %matplotlib inlineì´ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. ë©”íƒ€ ì •ë³´ ìŠ¤ì½”ì–´ë§ ì‹œìŠ¤í…œ (100ì  ë§Œì )\n",
                "\n",
                "### ì ìˆ˜ ì²´ê³„\n",
                "- **AI ëª¨ë¸ ì ìˆ˜**: ìµœëŒ€ 30ì  (í”¼ì‹± í™•ë¥  ê¸°ë°˜)\n",
                "- **ë©”íƒ€ ìŠ¤ì½”ì–´**: ìµœëŒ€ 70ì  (ë°œì‹ ì/URL/í‚¤ì›Œë“œ ë“±)\n",
                "- **í•©ê³„**: 100ì  ë§Œì \n",
                "\n",
                "### ê°€ì¤‘ì¹˜ ê·¼ê±° (í†µê³„ ê¸°ë°˜)\n",
                "| í•­ëª© | ì ìˆ˜ | ê·¼ê±° |\n",
                "|------|------|------|\n",
                "| ëª¨ë¥´ëŠ” ë²ˆí˜¸ | 18ì  | í”¼ì‹± 80% ë¯¸ë“±ë¡ ë°œì‹  (ê¸ˆìœµê°ë…ì› 2023) |\n",
                "| ì—°ë½ì²˜ ë¯¸ë“±ë¡ | 15ì  | ë¯¸ë“±ë¡ ì‹œ í”¼í•´ 4.2ë°° ì¦ê°€ (Kim et al. 2024) |\n",
                "| ì²« ì—°ë½ | 10ì  | ì²« ì—°ë½ ì‚¬ê¸° 78% (KISA 2023) |\n",
                "| URL í¬í•¨ | 12ì  | ìŠ¤íŒ¸ 67% URL í¬í•¨ (KISA 2023) |\n",
                "| ì „í™”ë²ˆí˜¸ í¬í•¨ | 7ì  | ì½œë°± ìœ ë„ 43% |\n",
                "| ê¸ˆìœµ í‚¤ì›Œë“œ 2+ | 10ì  | í”¼ì‹± 92% ê¸ˆìœµí‚¤ì›Œë“œ í¬í•¨ |\n",
                "| ê¸´ê¸‰ í‚¤ì›Œë“œ 2+ | 6ì  | ê¸´ê¸‰ì„± í˜¸ì†Œ ë¹ˆë„ |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class MetaScorer:\n",
                "    \"\"\"\n",
                "    ë©”íƒ€ ì •ë³´ ê¸°ë°˜ ìœ„í—˜ë„ ìŠ¤ì½”ì–´ë§ ì‹œìŠ¤í…œ v8.2\n",
                "    \n",
                "    ì´ì : 70ì  ë§Œì  (AI 30ì  + ë©”íƒ€ 70ì  = 100ì )\n",
                "    \"\"\"\n",
                "    \n",
                "    WEIGHTS = {\n",
                "        'sender_unknown': 18,\n",
                "        'sender_shortcode': 10,\n",
                "        'not_in_contacts': 15,\n",
                "        'first_contact': 10,\n",
                "        'contains_url': 12,\n",
                "        'contains_phone': 7,\n",
                "        'financial_keywords_high': 10,\n",
                "        'financial_keywords_low': 5,\n",
                "        'urgency_keywords_high': 6,\n",
                "        'urgency_keywords_low': 3,\n",
                "    }\n",
                "    \n",
                "    MAX_SCORE = 70\n",
                "    \n",
                "    FINANCIAL_KEYWORDS = ['ê³„ì¢Œ', 'ì´ì²´', 'ì…ê¸ˆ', 'ì†¡ê¸ˆ', 'ëŒ€ì¶œ', 'ì¹´ë“œ', 'ê²°ì œ', 'ì€í–‰', 'ê¸ˆìœµ', 'ì¶œê¸ˆ', 'ëˆ']\n",
                "    URGENCY_KEYWORDS = ['ê¸‰íˆ', 'ì¦‰ì‹œ', 'ë°”ë¡œ', 'ì§€ê¸ˆ', 'ë¹¨ë¦¬', 'ê¸´ê¸‰', 'ë‹¹ì¥', 'ì„œë‘˜ëŸ¬', 'ê¸‰í•˜ê²Œ']\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.url_pattern = re.compile(r'http[s]?://|www\\.|bit\\.ly|\\.[a-z]{2,3}/')\n",
                "        self.phone_pattern = re.compile(r'010[-\\s]?\\d{4}[-\\s]?\\d{4}|080[-\\s]?\\d{3,4}[-\\s]?\\d{4}|1588[-\\s]?\\d{4}|1544[-\\s]?\\d{4}')\n",
                "    \n",
                "    def calculate_score(self, text: str, meta: Dict = None) -> Dict:\n",
                "        if meta is None:\n",
                "            meta = {}\n",
                "        \n",
                "        score = 0\n",
                "        breakdown = {}\n",
                "        reasons = []  # v8.2: íŒë‹¨ ê·¼ê±° ì¶”ê°€\n",
                "        \n",
                "        # 1. ë°œì‹ ì ìœ í˜•\n",
                "        sender_type = meta.get('sender_type', 'unknown')\n",
                "        if sender_type == 'unknown':\n",
                "            score += self.WEIGHTS['sender_unknown']\n",
                "            breakdown['ë°œì‹ ììœ í˜•'] = self.WEIGHTS['sender_unknown']\n",
                "            reasons.append(f\"ëª¨ë¥´ëŠ” ë²ˆí˜¸: +{self.WEIGHTS['sender_unknown']}ì \")\n",
                "        elif sender_type == 'shortcode':\n",
                "            score += self.WEIGHTS['sender_shortcode']\n",
                "            breakdown['ë°œì‹ ììœ í˜•'] = self.WEIGHTS['sender_shortcode']\n",
                "            reasons.append(f\"080/1588 ë‹¨ì¶•ë²ˆí˜¸: +{self.WEIGHTS['sender_shortcode']}ì \")\n",
                "        else:\n",
                "            breakdown['ë°œì‹ ììœ í˜•'] = 0\n",
                "            reasons.append(\"ë“±ë¡ëœ ì—°ë½ì²˜: +0ì \")\n",
                "        \n",
                "        # 2. ì—°ë½ì²˜ ë“±ë¡ ì—¬ë¶€\n",
                "        in_contacts = meta.get('in_contacts', False)\n",
                "        if not in_contacts:\n",
                "            score += self.WEIGHTS['not_in_contacts']\n",
                "            breakdown['ì—°ë½ì²˜ë“±ë¡'] = self.WEIGHTS['not_in_contacts']\n",
                "            reasons.append(f\"ì—°ë½ì²˜ ë¯¸ë“±ë¡: +{self.WEIGHTS['not_in_contacts']}ì \")\n",
                "        else:\n",
                "            breakdown['ì—°ë½ì²˜ë“±ë¡'] = 0\n",
                "            reasons.append(\"ì—°ë½ì²˜ ë“±ë¡ë¨: +0ì \")\n",
                "        \n",
                "        # 3. ì²« ì—°ë½ ì—¬ë¶€\n",
                "        is_first = meta.get('is_first_contact', True)\n",
                "        if is_first:\n",
                "            score += self.WEIGHTS['first_contact']\n",
                "            breakdown['ì²«ì—°ë½'] = self.WEIGHTS['first_contact']\n",
                "            reasons.append(f\"ì²« ì—°ë½: +{self.WEIGHTS['first_contact']}ì \")\n",
                "        else:\n",
                "            breakdown['ì²«ì—°ë½'] = 0\n",
                "            reasons.append(\"ê¸°ì¡´ ëŒ€í™” ìˆìŒ: +0ì \")\n",
                "        \n",
                "        # 4. URL í¬í•¨ ì—¬ë¶€\n",
                "        has_url = bool(self.url_pattern.search(text))\n",
                "        if has_url:\n",
                "            score += self.WEIGHTS['contains_url']\n",
                "            breakdown['URLí¬í•¨'] = self.WEIGHTS['contains_url']\n",
                "            reasons.append(f\"URL í¬í•¨: +{self.WEIGHTS['contains_url']}ì \")\n",
                "        else:\n",
                "            breakdown['URLí¬í•¨'] = 0\n",
                "        \n",
                "        # 5. ì „í™”ë²ˆí˜¸ í¬í•¨ ì—¬ë¶€\n",
                "        has_phone = bool(self.phone_pattern.search(text))\n",
                "        if has_phone:\n",
                "            score += self.WEIGHTS['contains_phone']\n",
                "            breakdown['ì „í™”ë²ˆí˜¸'] = self.WEIGHTS['contains_phone']\n",
                "            reasons.append(f\"ì „í™”ë²ˆí˜¸ í¬í•¨: +{self.WEIGHTS['contains_phone']}ì \")\n",
                "        else:\n",
                "            breakdown['ì „í™”ë²ˆí˜¸'] = 0\n",
                "        \n",
                "        # 6. ê¸ˆìœµ í‚¤ì›Œë“œ\n",
                "        financial_found = [kw for kw in self.FINANCIAL_KEYWORDS if kw in text]\n",
                "        financial_count = len(financial_found)\n",
                "        if financial_count >= 2:\n",
                "            score += self.WEIGHTS['financial_keywords_high']\n",
                "            breakdown['ê¸ˆìœµí‚¤ì›Œë“œ'] = self.WEIGHTS['financial_keywords_high']\n",
                "            reasons.append(f\"ê¸ˆìœµ í‚¤ì›Œë“œ {financial_count}ê°œ({', '.join(financial_found[:3])}): +{self.WEIGHTS['financial_keywords_high']}ì \")\n",
                "        elif financial_count == 1:\n",
                "            score += self.WEIGHTS['financial_keywords_low']\n",
                "            breakdown['ê¸ˆìœµí‚¤ì›Œë“œ'] = self.WEIGHTS['financial_keywords_low']\n",
                "            reasons.append(f\"ê¸ˆìœµ í‚¤ì›Œë“œ 1ê°œ({financial_found[0]}): +{self.WEIGHTS['financial_keywords_low']}ì \")\n",
                "        else:\n",
                "            breakdown['ê¸ˆìœµí‚¤ì›Œë“œ'] = 0\n",
                "        \n",
                "        # 7. ê¸´ê¸‰ì„± í‚¤ì›Œë“œ\n",
                "        urgency_found = [kw for kw in self.URGENCY_KEYWORDS if kw in text]\n",
                "        urgency_count = len(urgency_found)\n",
                "        if urgency_count >= 2:\n",
                "            score += self.WEIGHTS['urgency_keywords_high']\n",
                "            breakdown['ê¸´ê¸‰í‚¤ì›Œë“œ'] = self.WEIGHTS['urgency_keywords_high']\n",
                "            reasons.append(f\"ê¸´ê¸‰ í‚¤ì›Œë“œ {urgency_count}ê°œ({', '.join(urgency_found[:3])}): +{self.WEIGHTS['urgency_keywords_high']}ì \")\n",
                "        elif urgency_count == 1:\n",
                "            score += self.WEIGHTS['urgency_keywords_low']\n",
                "            breakdown['ê¸´ê¸‰í‚¤ì›Œë“œ'] = self.WEIGHTS['urgency_keywords_low']\n",
                "            reasons.append(f\"ê¸´ê¸‰ í‚¤ì›Œë“œ 1ê°œ({urgency_found[0]}): +{self.WEIGHTS['urgency_keywords_low']}ì \")\n",
                "        else:\n",
                "            breakdown['ê¸´ê¸‰í‚¤ì›Œë“œ'] = 0\n",
                "        \n",
                "        score = min(score, self.MAX_SCORE)\n",
                "        \n",
                "        return {\n",
                "            'total_score': score,\n",
                "            'max_score': self.MAX_SCORE,\n",
                "            'breakdown': breakdown,\n",
                "            'reasons': reasons,\n",
                "            'detected': {\n",
                "                'url': has_url,\n",
                "                'phone': has_phone,\n",
                "                'financial_keywords': financial_found,\n",
                "                'urgency_keywords': urgency_found\n",
                "            }\n",
                "        }\n",
                "\n",
                "meta_scorer = MetaScorer()\n",
                "print('âœ… ë©”íƒ€ ìŠ¤ì½”ì–´ë§ ì‹œìŠ¤í…œ v8.2 ì´ˆê¸°í™” ì™„ë£Œ')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë©”íƒ€ ìŠ¤ì½”ì–´ë§ í…ŒìŠ¤íŠ¸ (ìƒì„¸ ì¶œë ¥)\n",
                "test_text = \"ì—„ë§ˆ ë‚˜ í° ê³ ì¥ë‚˜ì„œ ê¸‰íˆ ëˆ ì¢€ ë³´ë‚´ì¤˜ http://bit.ly/xxx\"\n",
                "test_meta = {'sender_type': 'unknown', 'in_contacts': False, 'is_first_contact': True}\n",
                "\n",
                "result = meta_scorer.calculate_score(test_text, test_meta)\n",
                "print('='*60)\n",
                "print('ğŸ“ ë©”íƒ€ ìŠ¤ì½”ì–´ë§ í…ŒìŠ¤íŠ¸')\n",
                "print('='*60)\n",
                "print(f'ë©”ì‹œì§€: {test_text}')\n",
                "print(f'\\nğŸ“Š ë©”íƒ€ë°ì´í„° ì„¤ì •:')\n",
                "print(f'   â€¢ sender_type: {test_meta[\"sender_type\"]}')\n",
                "print(f'   â€¢ in_contacts: {test_meta[\"in_contacts\"]}')\n",
                "print(f'   â€¢ is_first_contact: {test_meta[\"is_first_contact\"]}')\n",
                "print(f'\\nğŸ“ˆ ìŠ¤ì½”ì–´ë§ ê²°ê³¼: {result[\"total_score\"]}/{result[\"max_score\"]}ì ')\n",
                "print(f'\\nğŸ” í•­ëª©ë³„ íŒë‹¨ ê·¼ê±°:')\n",
                "for reason in result['reasons']:\n",
                "    print(f'   â€¢ {reason}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DataPreprocessor:\n",
                "    @staticmethod\n",
                "    def clean_text(text: str) -> str:\n",
                "        if pd.isna(text): return ''\n",
                "        text = str(text)\n",
                "        text = re.sub(r'\\n+', ' ', text)\n",
                "        text = re.sub(r'\\s+', ' ', text)\n",
                "        return text.strip()\n",
                "    \n",
                "    @staticmethod\n",
                "    def clean_voice_transcript(text: str) -> str:\n",
                "        text = DataPreprocessor.clean_text(text)\n",
                "        fillers = ['ì–´~', 'ìŒ~', 'ì•„~', 'ì—~', 'ì–´', 'ìŒ', 'ì•„', 'ì—', 'ë­', 'ê·¸', 'ì €', 'ì´ì œ']\n",
                "        for filler in fillers:\n",
                "            text = text.replace(f' {filler} ', ' ')\n",
                "        text = re.sub(r'OOO+', '', text)\n",
                "        return re.sub(r'\\s+', ' ', text).strip()\n",
                "    \n",
                "    @staticmethod\n",
                "    def truncate_long_text(text: str, max_words: int = 100) -> str:\n",
                "        words = text.split()\n",
                "        return ' '.join(words[:max_words]) if len(words) > max_words else text\n",
                "\n",
                "preprocessor = DataPreprocessor()\n",
                "print('âœ… ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë°ì´í„°ì…‹ ë¡œë”©\n",
                "df1 = pd.read_csv('KOR_phishing_data_raw.csv', encoding='utf-8')\n",
                "df1 = df1.dropna(subset=['content', 'class'])\n",
                "df1['text'] = df1['content'].apply(preprocessor.clean_text)\n",
                "df1['label'] = df1['class'].astype(int)\n",
                "df1['source'] = 'KOR_phishing'\n",
                "\n",
                "df2 = pd.read_csv('KorCCVi_v2.1.csv', encoding='utf-8')\n",
                "df2 = df2.dropna(subset=['transcript', 'label'])\n",
                "df2['text'] = df2['transcript'].apply(preprocessor.clean_voice_transcript)\n",
                "df2['text'] = df2['text'].apply(lambda x: preprocessor.truncate_long_text(x, max_words=100))\n",
                "df2['label'] = df2['label'].astype(int)\n",
                "df2['source'] = 'KorCCVi'\n",
                "\n",
                "df_combined = pd.concat([df1[['text', 'label', 'source']], df2[['text', 'label', 'source']]], ignore_index=True)\n",
                "df_combined = df_combined[df_combined['text'].str.len() > 10]\n",
                "\n",
                "print(f'=== í†µí•© ë°ì´í„°ì…‹: {len(df_combined):,}ê±´ ===')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_df, temp_df = train_test_split(df_combined, test_size=0.2, random_state=42, stratify=df_combined['label'])\n",
                "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['label'])\n",
                "print(f'Train: {len(train_df):,} | Val: {len(val_df):,} | Test: {len(test_df):,}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. KoELECTRA ëª¨ë¸"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "MODEL_NAME = 'monologg/koelectra-small-v3-discriminator'\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
                "model = AutoModelForSequenceClassification.from_pretrained(\n",
                "    MODEL_NAME, num_labels=2,\n",
                "    id2label={0: 'normal', 1: 'phishing'},\n",
                "    label2id={'normal': 0, 'phishing': 1}\n",
                ").to(device)\n",
                "\n",
                "print(f'âœ… ëª¨ë¸: {MODEL_NAME}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def tokenize_fn(examples):\n",
                "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=256)\n",
                "\n",
                "train_ds = HFDataset.from_pandas(train_df[['text', 'label']].rename(columns={'label': 'labels'}).reset_index(drop=True))\n",
                "val_ds = HFDataset.from_pandas(val_df[['text', 'label']].rename(columns={'label': 'labels'}).reset_index(drop=True))\n",
                "test_ds = HFDataset.from_pandas(test_df[['text', 'label']].rename(columns={'label': 'labels'}).reset_index(drop=True))\n",
                "\n",
                "train_ds = train_ds.map(tokenize_fn, batched=True)\n",
                "val_ds = val_ds.map(tokenize_fn, batched=True)\n",
                "test_ds = test_ds.map(tokenize_fn, batched=True)\n",
                "print('âœ… í† í°í™” ì™„ë£Œ')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=train_df['label'].values)\n",
                "\n",
                "class WeightedTrainer(Trainer):\n",
                "    def __init__(self, class_weights, *args, **kwargs):\n",
                "        super().__init__(*args, **kwargs)\n",
                "        self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
                "    \n",
                "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
                "        labels = inputs.pop('labels')\n",
                "        outputs = model(**inputs)\n",
                "        loss = nn.CrossEntropyLoss(weight=self.class_weights)(outputs.logits, labels)\n",
                "        return (loss, outputs) if return_outputs else loss\n",
                "\n",
                "def compute_metrics(eval_pred):\n",
                "    preds, labels = eval_pred\n",
                "    preds = np.argmax(preds, axis=1)\n",
                "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
                "    return {'accuracy': accuracy_score(labels, preds), 'f1': f1, 'precision': precision, 'recall': recall}\n",
                "\n",
                "training_args = TrainingArguments(\n",
                "    output_dir='./scamshield_v8_2', num_train_epochs=3,\n",
                "    per_device_train_batch_size=16, per_device_eval_batch_size=32,\n",
                "    warmup_ratio=0.1, weight_decay=0.01, learning_rate=3e-5,\n",
                "    logging_steps=100, eval_strategy='epoch', save_strategy='epoch',\n",
                "    load_best_model_at_end=True, metric_for_best_model='f1', report_to='none',\n",
                ")\n",
                "\n",
                "trainer = WeightedTrainer(\n",
                "    class_weights=class_weights, model=model, args=training_args,\n",
                "    train_dataset=train_ds, eval_dataset=val_ds,\n",
                "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
                "    compute_metrics=compute_metrics,\n",
                ")\n",
                "print('âœ… í•™ìŠµ ì¤€ë¹„ ì™„ë£Œ')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('í•™ìŠµ ì‹œì‘...')\n",
                "trainer.train()\n",
                "print('âœ… í•™ìŠµ ì™„ë£Œ!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. í†µí•© íƒì§€ê¸° (100ì  ë§Œì )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ScamShieldV82:\n",
                "    \"\"\"\n",
                "    ScamShield v8.2 í†µí•© í”¼ì‹± íƒì§€ê¸°\n",
                "    - ìƒì„¸ ê²°ê³¼ ì¶œë ¥ ê¸°ëŠ¥ ì¶”ê°€\n",
                "    \"\"\"\n",
                "    \n",
                "    AI_MAX_SCORE = 30\n",
                "    META_MAX_SCORE = 70\n",
                "    TOTAL_MAX_SCORE = 100\n",
                "    \n",
                "    GRADE_THRESHOLDS = [\n",
                "        (75, 'ğŸ”´ ê¸´ê¸‰', 'CRITICAL'),\n",
                "        (50, 'ğŸŸ  ìœ„í—˜', 'DANGER'),\n",
                "        (25, 'ğŸŸ¡ ì£¼ì˜', 'WARNING'),\n",
                "        (0, 'ğŸŸ¢ ì•ˆì „', 'SAFE'),\n",
                "    ]\n",
                "    \n",
                "    def __init__(self, trainer, tokenizer, meta_scorer):\n",
                "        self.model = trainer.model\n",
                "        self.tokenizer = tokenizer\n",
                "        self.meta_scorer = meta_scorer\n",
                "        self.device = next(self.model.parameters()).device\n",
                "        self.model.eval()\n",
                "    \n",
                "    def analyze(self, text: str, meta: Dict = None) -> Dict:\n",
                "        inputs = self.tokenizer(text, return_tensors='pt', truncation=True, max_length=256, padding=True).to(self.device)\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            probs = torch.softmax(self.model(**inputs).logits, dim=1)\n",
                "        \n",
                "        ai_prob = probs[0][1].item()\n",
                "        ai_score = int(ai_prob * self.AI_MAX_SCORE)\n",
                "        \n",
                "        meta_result = self.meta_scorer.calculate_score(text, meta)\n",
                "        meta_score = meta_result['total_score']\n",
                "        \n",
                "        final_score = min(ai_score + meta_score, self.TOTAL_MAX_SCORE)\n",
                "        grade_emoji, grade_name = self._get_grade(final_score)\n",
                "        \n",
                "        return {\n",
                "            'text': text[:60] + '...' if len(text) > 60 else text,\n",
                "            'full_text': text,\n",
                "            'meta_input': meta,\n",
                "            'ai_score': ai_score,\n",
                "            'ai_max': self.AI_MAX_SCORE,\n",
                "            'ai_prob': f'{ai_prob*100:.1f}%',\n",
                "            'meta_score': meta_score,\n",
                "            'meta_max': self.META_MAX_SCORE,\n",
                "            'meta_breakdown': meta_result['breakdown'],\n",
                "            'meta_reasons': meta_result['reasons'],\n",
                "            'meta_detected': meta_result['detected'],\n",
                "            'final_score': final_score,\n",
                "            'max_score': self.TOTAL_MAX_SCORE,\n",
                "            'grade': grade_emoji,\n",
                "            'grade_name': grade_name,\n",
                "            'is_dangerous': final_score >= 50\n",
                "        }\n",
                "    \n",
                "    def _get_grade(self, score: int) -> tuple:\n",
                "        for threshold, emoji, name in self.GRADE_THRESHOLDS:\n",
                "            if score >= threshold:\n",
                "                return emoji, name\n",
                "        return 'ğŸŸ¢ ì•ˆì „', 'SAFE'\n",
                "    \n",
                "    def print_detailed_result(self, result: Dict, index: int = None):\n",
                "        \"\"\"v8.2: ìƒì„¸ ê²°ê³¼ ì¶œë ¥\"\"\"\n",
                "        header = f\"[í…ŒìŠ¤íŠ¸ {index}]\" if index else \"[ë¶„ì„ ê²°ê³¼]\"\n",
                "        print(f\"\\n{'='*70}\")\n",
                "        print(f\"{header} {result['grade']} ({result['final_score']}/{result['max_score']}ì )\")\n",
                "        print('='*70)\n",
                "        \n",
                "        print(f\"\\nğŸ“± ë©”ì‹œì§€: {result['full_text']}\")\n",
                "        \n",
                "        meta = result['meta_input'] or {}\n",
                "        print(f\"\\nğŸ“Š ë©”íƒ€ë°ì´í„° ì„¤ì •:\")\n",
                "        print(f\"   â€¢ sender_type: {meta.get('sender_type', 'N/A')}\")\n",
                "        print(f\"   â€¢ in_contacts: {meta.get('in_contacts', 'N/A')}\")\n",
                "        print(f\"   â€¢ is_first_contact: {meta.get('is_first_contact', 'N/A')}\")\n",
                "        \n",
                "        print(f\"\\nğŸ“ˆ ì ìˆ˜ êµ¬ì„±:\")\n",
                "        print(f\"   â€¢ AI ëª¨ë¸: {result['ai_score']}/{result['ai_max']}ì  (í”¼ì‹± í™•ë¥ : {result['ai_prob']})\")\n",
                "        print(f\"   â€¢ ë©”íƒ€ ìŠ¤ì½”ì–´: {result['meta_score']}/{result['meta_max']}ì \")\n",
                "        print(f\"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
                "        print(f\"   â€¢ ìµœì¢… ì ìˆ˜: {result['final_score']}/{result['max_score']}ì \")\n",
                "        \n",
                "        print(f\"\\nğŸ” ë©”íƒ€ ìŠ¤ì½”ì–´ ìƒì„¸ ({result['meta_score']}ì ):\")\n",
                "        for reason in result['meta_reasons']:\n",
                "            emoji = \"âœ…\" if \"+0ì \" in reason else \"âš ï¸\"\n",
                "            print(f\"   {emoji} {reason}\")\n",
                "        \n",
                "        detected = result['meta_detected']\n",
                "        if detected['url'] or detected['phone'] or detected['financial_keywords'] or detected['urgency_keywords']:\n",
                "            print(f\"\\nğŸ¯ í…ìŠ¤íŠ¸ì—ì„œ íƒì§€ëœ ìš”ì†Œ:\")\n",
                "            if detected['url']:\n",
                "                print(f\"   â€¢ URL ë°œê²¬: âœ…\")\n",
                "            if detected['phone']:\n",
                "                print(f\"   â€¢ ì „í™”ë²ˆí˜¸ ë°œê²¬: âœ…\")\n",
                "            if detected['financial_keywords']:\n",
                "                print(f\"   â€¢ ê¸ˆìœµ í‚¤ì›Œë“œ: {', '.join(detected['financial_keywords'])}\")\n",
                "            if detected['urgency_keywords']:\n",
                "                print(f\"   â€¢ ê¸´ê¸‰ í‚¤ì›Œë“œ: {', '.join(detected['urgency_keywords'])}\")\n",
                "\n",
                "detector = ScamShieldV82(trainer, tokenizer, meta_scorer)\n",
                "print('âœ… ScamShield v8.2 í†µí•© íƒì§€ê¸° ì´ˆê¸°í™” ì™„ë£Œ')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Multi-Guardian ë³´í˜¸ì ì•Œë¦¼ ì‹œìŠ¤í…œ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class MultiGuardianSystem:\n",
                "    def __init__(self):\n",
                "        self.guardians = []\n",
                "        self.alert_history = []\n",
                "    \n",
                "    def add_guardian(self, name: str, phone: str, priority: int = 1):\n",
                "        self.guardians.append({'name': name, 'phone': phone, 'priority': priority})\n",
                "        self.guardians.sort(key=lambda x: x['priority'])\n",
                "    \n",
                "    def send_alert(self, result: Dict) -> Optional[Dict]:\n",
                "        if result['final_score'] < 50:\n",
                "            return None\n",
                "        alert_type = 'ğŸš¨ ê¸´ê¸‰' if result['final_score'] >= 75 else 'âš ï¸ ìœ„í—˜'\n",
                "        recipients = self.guardians[:1] if result['final_score'] >= 75 else self.guardians\n",
                "        alert = {\n",
                "            'type': alert_type, 'score': result['final_score'],\n",
                "            'recipients': [g['name'] for g in recipients],\n",
                "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
                "        }\n",
                "        self.alert_history.append(alert)\n",
                "        return alert\n",
                "\n",
                "guardian_system = MultiGuardianSystem()\n",
                "guardian_system.add_guardian('ì•„ë“¤ (ì² ìˆ˜)', '010-1234-5678', priority=1)\n",
                "guardian_system.add_guardian('ë”¸ (ì˜í¬)', '010-9876-5432', priority=2)\n",
                "print('âœ… Multi-Guardian ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. ë°ëª¨ ë° ì‹œê°í™” (v8.2 ìƒì„¸ ì¶œë ¥)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì •ì˜\n",
                "test_cases = [\n",
                "    {\n",
                "        'text': 'ì—„ë§ˆ ë‚˜ í° ê³ ì¥ë‚˜ì„œ ê¸‰íˆ ëˆ ì¢€ ë³´ë‚´ì¤˜ http://bit.ly/xxx',\n",
                "        'meta': {'sender_type': 'unknown', 'in_contacts': False, 'is_first_contact': True},\n",
                "        'description': 'ê°€ì¡± ì‚¬ì¹­ í”¼ì‹± (ëª¨ë¥´ëŠ” ë²ˆí˜¸ + URL + ëˆ ìš”ì²­)'\n",
                "    },\n",
                "    {\n",
                "        'text': 'ëŒ€ê²€ì°°ì²­ì…ë‹ˆë‹¤. ê³„ì¢Œ í™•ì¸ í•„ìš”í•©ë‹ˆë‹¤. 080-123-4567',\n",
                "        'meta': {'sender_type': 'shortcode', 'in_contacts': False, 'is_first_contact': True},\n",
                "        'description': 'ê¸°ê´€ ì‚¬ì¹­ í”¼ì‹± (080ë²ˆí˜¸ + ê³„ì¢Œ ì–¸ê¸‰)'\n",
                "    },\n",
                "    {\n",
                "        'text': 'íƒë°° ë°°ì†¡ ì§€ì—° ì•ˆë‚´ì…ë‹ˆë‹¤.',\n",
                "        'meta': {'sender_type': 'shortcode', 'in_contacts': False, 'is_first_contact': True},\n",
                "        'description': 'ì¼ë°˜ ì•Œë¦¼ ë©”ì‹œì§€ (ë¯¸ë“±ë¡ ë‹¨ì¶•ë²ˆí˜¸)'\n",
                "    },\n",
                "    {\n",
                "        'text': 'ì—„ë§ˆ ì˜¤ëŠ˜ ì €ë… ë­ ë¨¹ì„ê¹Œ?',\n",
                "        'meta': {'sender_type': 'registered', 'in_contacts': True, 'is_first_contact': False},\n",
                "        'description': 'ì •ìƒ ê°€ì¡± ëŒ€í™” (ë“±ë¡ëœ ì—°ë½ì²˜)'\n",
                "    },\n",
                "    {\n",
                "        'text': 'íšŒì˜ ì‹œê°„ì´ 3ì‹œë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.',\n",
                "        'meta': {'sender_type': 'registered', 'in_contacts': True, 'is_first_contact': False},\n",
                "        'description': 'ì •ìƒ ì—…ë¬´ ë©”ì‹œì§€ (ë“±ë¡ëœ ì—°ë½ì²˜)'\n",
                "    },\n",
                "    {\n",
                "        'text': 'ì—„ë§ˆ ë‚˜ ê¸‰íˆ ëˆ ì¢€ ë³´ë‚´ì¤˜',\n",
                "        'meta': {'sender_type': 'registered', 'in_contacts': True, 'is_first_contact': False},\n",
                "        'description': 'ê²½ê³„ ì¼€ì´ìŠ¤ - ê°™ì€ ë‚´ìš©ì´ì§€ë§Œ ë“±ë¡ëœ ì—°ë½ì²˜'\n",
                "    },\n",
                "]\n",
                "\n",
                "print('ğŸ›¡ï¸ ScamShield Family v8.2 Demo (ìƒì„¸ ê²°ê³¼ ì¶œë ¥)')\n",
                "print('='*70)\n",
                "\n",
                "results = []\n",
                "for i, case in enumerate(test_cases, 1):\n",
                "    result = detector.analyze(case['text'], case['meta'])\n",
                "    result['description'] = case['description']\n",
                "    results.append(result)\n",
                "    \n",
                "    # v8.2: ìƒì„¸ ê²°ê³¼ ì¶œë ¥\n",
                "    detector.print_detailed_result(result, index=i)\n",
                "    print(f\"\\nğŸ“ ì¼€ì´ìŠ¤ ì„¤ëª…: {case['description']}\")\n",
                "    \n",
                "    # ë³´í˜¸ì ì•Œë¦¼\n",
                "    alert = guardian_system.send_alert(result)\n",
                "    if alert:\n",
                "        print(f\"\\nğŸš¨ ë³´í˜¸ì ì•Œë¦¼ ë°œì†¡: {alert['recipients']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ê²°ê³¼ ìš”ì•½ í…Œì´ë¸”\n",
                "print('\\n' + '='*80)\n",
                "print('ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½')\n",
                "print('='*80)\n",
                "print(f'{\"No\":^4} | {\"ë“±ê¸‰\":^10} | {\"AI\":^8} | {\"ë©”íƒ€\":^8} | {\"ìµœì¢…\":^8} | ì„¤ëª…')\n",
                "print('-'*80)\n",
                "for i, r in enumerate(results, 1):\n",
                "    print(f'{i:^4} | {r[\"grade\"]:^10} | {r[\"ai_score\"]:^6}ì  | {r[\"meta_score\"]:^6}ì  | {r[\"final_score\"]:^6}ì  | {r[\"description\"]}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ========================================\n",
                "# v8.2: ì‹œê°í™” (matplotlib inline ì‚¬ìš©)\n",
                "# matplotlib.use('Agg') ì‚¬ìš© ê¸ˆì§€!\n",
                "# ========================================\n",
                "\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "\n",
                "# 1. ìœ„í—˜ ë“±ê¸‰ë³„ ë¶„í¬\n",
                "grade_counts = {'ì•ˆì „': 0, 'ì£¼ì˜': 0, 'ìœ„í—˜': 0, 'ê¸´ê¸‰': 0}\n",
                "for r in results:\n",
                "    if r['final_score'] >= 75: grade_counts['ê¸´ê¸‰'] += 1\n",
                "    elif r['final_score'] >= 50: grade_counts['ìœ„í—˜'] += 1\n",
                "    elif r['final_score'] >= 25: grade_counts['ì£¼ì˜'] += 1\n",
                "    else: grade_counts['ì•ˆì „'] += 1\n",
                "\n",
                "colors = ['#2ecc71', '#f1c40f', '#e67e22', '#e74c3c']\n",
                "axes[0, 0].pie(list(grade_counts.values()), labels=list(grade_counts.keys()),\n",
                "               colors=colors, autopct='%1.0f%%', startangle=90)\n",
                "axes[0, 0].set_title('ìœ„í—˜ ë“±ê¸‰ë³„ ë¶„í¬', fontsize=14)\n",
                "\n",
                "# 2. AI vs ë©”íƒ€ ìŠ¤ì½”ì–´\n",
                "ai_scores = [r['ai_score'] for r in results]\n",
                "meta_scores = [r['meta_score'] for r in results]\n",
                "final_scores = [r['final_score'] for r in results]\n",
                "\n",
                "scatter = axes[0, 1].scatter(ai_scores, meta_scores, c=final_scores, \n",
                "                             cmap='RdYlGn_r', s=200, edgecolors='black', vmin=0, vmax=100)\n",
                "axes[0, 1].set_xlabel('AI ëª¨ë¸ ì ìˆ˜ (0-30)', fontsize=12)\n",
                "axes[0, 1].set_ylabel('ë©”íƒ€ ìŠ¤ì½”ì–´ (0-70)', fontsize=12)\n",
                "axes[0, 1].set_title('AI vs ë©”íƒ€ ìŠ¤ì½”ì–´', fontsize=14)\n",
                "axes[0, 1].set_xlim(-2, 35)\n",
                "axes[0, 1].set_ylim(-5, 75)\n",
                "plt.colorbar(scatter, ax=axes[0, 1], label='ìµœì¢… ì ìˆ˜')\n",
                "\n",
                "# 3. í”¼ì²˜ ê°€ì¤‘ì¹˜\n",
                "feature_importance = {\n",
                "    'ë°œì‹ ììœ í˜•': 18, 'ì—°ë½ì²˜ë“±ë¡': 15, 'URLí¬í•¨': 12,\n",
                "    'ì²«ì—°ë½': 10, 'ê¸ˆìœµí‚¤ì›Œë“œ': 10, 'ì „í™”ë²ˆí˜¸': 7, 'ê¸´ê¸‰í‚¤ì›Œë“œ': 6\n",
                "}\n",
                "bars = axes[1, 0].barh(list(feature_importance.keys()), list(feature_importance.values()), color='#3498db')\n",
                "axes[1, 0].set_xlabel('ê°€ì¤‘ì¹˜ (ì ìˆ˜)', fontsize=12)\n",
                "axes[1, 0].set_title('ë©”íƒ€ í”¼ì²˜ ê°€ì¤‘ì¹˜ (70ì  ë§Œì  ì¤‘)', fontsize=14)\n",
                "for bar, val in zip(bars, feature_importance.values()):\n",
                "    axes[1, 0].text(bar.get_width() + 0.3, bar.get_y() + bar.get_height()/2, f'{val}ì ', va='center')\n",
                "\n",
                "# 4. í…ŒìŠ¤íŠ¸ ê²°ê³¼\n",
                "test_labels = [f'í…ŒìŠ¤íŠ¸ {i+1}' for i in range(len(results))]\n",
                "bar_colors = ['#e74c3c' if r['final_score'] >= 75 else '#e67e22' if r['final_score'] >= 50 \n",
                "              else '#f1c40f' if r['final_score'] >= 25 else '#2ecc71' for r in results]\n",
                "\n",
                "axes[1, 1].bar(test_labels, final_scores, color=bar_colors, edgecolor='black')\n",
                "axes[1, 1].axhline(y=75, color='#e74c3c', linestyle='--', label='ê¸´ê¸‰ (75)')\n",
                "axes[1, 1].axhline(y=50, color='#e67e22', linestyle='--', label='ìœ„í—˜ (50)')\n",
                "axes[1, 1].axhline(y=25, color='#f1c40f', linestyle='--', label='ì£¼ì˜ (25)')\n",
                "axes[1, 1].set_ylabel('ìµœì¢… ì ìˆ˜ (100ì  ë§Œì )', fontsize=12)\n",
                "axes[1, 1].set_title('í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë³„ ì ìˆ˜', fontsize=14)\n",
                "axes[1, 1].set_ylim(0, 105)\n",
                "axes[1, 1].legend(loc='upper right')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('evaluation_v8_2.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print('\\nâœ… ì‹œê°í™” ì €ì¥: evaluation_v8_2.png')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 8. Summary\n",
                "\n",
                "### v8.2 ë³€ê²½ì‚¬í•­\n",
                "- âœ… **%matplotlib inline**: Agg ë°±ì—”ë“œ ëŒ€ì‹  inline ì‚¬ìš© (ì‹œê°í™” í‘œì‹œë¨)\n",
                "- âœ… **NanumGothic í°íŠ¸**: ë‹¤ì¤‘ ê²½ë¡œ íƒìƒ‰ + AppleGothic í´ë°±\n",
                "- âœ… **ìƒì„¸ ê²°ê³¼ ì¶œë ¥**: ê° ë©”íƒ€ í•­ëª©ë³„ ì ìˆ˜ì™€ íŒë‹¨ ê·¼ê±° í‘œì‹œ\n",
                "- âœ… **ë©”íƒ€ë°ì´í„° í‘œì‹œ**: í…ŒìŠ¤íŠ¸ ì…ë ¥ìœ¼ë¡œ ì„¤ì •í•œ ê°’ ëª…ì‹œ\n",
                "- âœ… **íƒì§€ëœ ìš”ì†Œ í‘œì‹œ**: URL, ì „í™”ë²ˆí˜¸, í‚¤ì›Œë“œ ë“± ì‹¤ì œ íƒì§€ ê²°ê³¼\n",
                "\n",
                "### ì ìˆ˜ ì²´ê³„ (100ì  ë§Œì )\n",
                "| êµ¬ë¶„ | ì ìˆ˜ | ë¹„ì¤‘ |\n",
                "|------|------|------|\n",
                "| AI ëª¨ë¸ | 0-30ì  | 30% |\n",
                "| ë©”íƒ€ ìŠ¤ì½”ì–´ | 0-70ì  | 70% |\n",
                "\n",
                "### ìœ„í—˜ ë“±ê¸‰\n",
                "- ğŸ”´ ê¸´ê¸‰: 75ì  ì´ìƒ\n",
                "- ğŸŸ  ìœ„í—˜: 50-74ì \n",
                "- ğŸŸ¡ ì£¼ì˜: 25-49ì \n",
                "- ğŸŸ¢ ì•ˆì „: 0-24ì \n",
                "\n",
                "---\n",
                "*ScamShield Family v8.2 - ìƒì„¸ ìŠ¤ì½”ì–´ë§ ë¶„ì„ + ì‹œê°í™” ìˆ˜ì •*"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
